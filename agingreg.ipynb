{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "103eab67-8aa7-4ba3-856f-15f41d2b4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ddc132-9621-40b7-87de-821eaa01e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.use(\"TkAgg\")\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(img)\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d01fc00-119b-42fe-89f7-f158cf0c87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model_pre = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    for param in model_pre.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(model_pre.fc.in_features)\n",
    "    model_pre.fc = nn.Sequential(\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.BatchNorm1d(4096),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Linear(4096, 512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        nn.Linear(model_pre.fc.in_features, 4),\n",
    "        nn.LogSoftmax(dim=1),\n",
    "    )\n",
    "    return model_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99462e8-0b57-45c5-9116-729b345431ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch, writer,num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0  # 初始化\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "    writer.add_scalar(str(num_epochs)+\"--Train loss\", total_loss / len(train_loader), epoch)\n",
    "    writer.flush()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, writer,num_epochs):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0.0\n",
    "    totel_test = 0.0\n",
    "    best_model = ''\n",
    "    best_accuract = 0.0\n",
    "    best_epoch = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_id, (data, target) in enumerate(test_loader):\n",
    "        # for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            _, preds = torch.max(output, dim=1)\n",
    "            correct += torch.sum(preds == target)\n",
    "            totel_test += len(target)\n",
    "        # total_loss /= totel_test\n",
    "        accuracy = correct / totel_test\n",
    "        writer.add_scalar(str(num_epochs)+\"Test loss\", total_loss, epoch)\n",
    "        writer.add_scalar(str(num_epochs)+\"Accuracy\", accuracy, epoch)\n",
    "        writer.flush()\n",
    "        print(\"Test Loss:{:.4f},Accuracy:{:.4f}\".format(total_loss, accuracy))\n",
    "        if accuracy>best_accuract:\n",
    "            best_model = model\n",
    "            best_accuract = accuracy\n",
    "            best_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ffba91-ab30-42c3-826a-1907040426ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(num_epochs,batch_size):\n",
    "    writer = SummaryWriter(\"./logs\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    250,\n",
    "                ),\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(250),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "    data_path = \"./data/oe\"\n",
    "    # image_datasets = {        x: datasets.ImageFolder(os.path.join(data_path, x), data_transforms[x])\n",
    "    #     for x in [\"train\", \"valid\"]\n",
    "    # }\n",
    "    # dataloaders = {\n",
    "    #     x: torch.utils.data.DataLoader(\n",
    "    #         dataset=image_datasets[x], batch_size=batch_size, shuffle=True\n",
    "    #     )\n",
    "    #     for x in [\"train\", \"valid\"]\n",
    "    # }\n",
    "    # data_size = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "    all_datasets = datasets.ImageFolder(os.path.join(data_path, \"train\"),data_transforms['train'])\n",
    "    print(len(all_datasets))\n",
    "    image_datasets={}\n",
    "    image_datasets[\"train\"], image_datasets[\"valid\"] = torch.utils.data.random_split(all_datasets, [160,32])\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(\n",
    "            dataset=image_datasets[x], batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        for x in [\"train\", \"valid\"]\n",
    "    }\n",
    "    data_size = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "    # target_names = image_datasets[\"train\"].classes\n",
    "    images, targets = next(iter(dataloaders[\"train\"]))\n",
    "    writer.add_images(\"chenpi\", images)\n",
    "    writer.flush()\n",
    "    # out = make_grid(images, nrow=4, padding=10)\n",
    "    # img_show(out, title=[target_names[x] for x in targets])\n",
    "    # show(out)\n",
    "\n",
    "    model = get_model().to(device)\n",
    "    # 优化器\n",
    "    optim_fit = torch.optim.Adam(model.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim_fit, step_size=10, gamma=0.1)\n",
    "    criterion = nn.NLLLoss()\n",
    "    print(len(dataloaders['train']))\n",
    "\n",
    "    print(len(dataloaders['valid']))\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"训练迭代：%d\" % epoch)\n",
    "        train(model, device, dataloaders[\"train\"], criterion, optim_fit, epoch, writer,num_epochs)\n",
    "        test(model, device, dataloaders[\"valid\"], criterion, epoch, writer,num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adddaa-f78d-49dc-a29e-56968701108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "2048\n",
      "20\n",
      "4\n",
      "训练迭代：0\n",
      "Test Loss:4.9755,Accuracy:0.5000\n",
      "训练迭代：1\n",
      "Test Loss:4.2566,Accuracy:0.6250\n",
      "训练迭代：2\n",
      "Test Loss:3.6695,Accuracy:0.7812\n",
      "训练迭代：3\n",
      "Test Loss:3.4077,Accuracy:0.7188\n",
      "训练迭代：4\n",
      "Test Loss:3.2483,Accuracy:0.7188\n",
      "训练迭代：5\n",
      "Test Loss:3.2859,Accuracy:0.7500\n",
      "训练迭代：6\n",
      "Test Loss:2.7859,Accuracy:0.7500\n",
      "训练迭代：7\n",
      "Test Loss:3.2455,Accuracy:0.6875\n",
      "训练迭代：8\n",
      "Test Loss:3.1163,Accuracy:0.6875\n",
      "训练迭代：9\n",
      "Test Loss:2.8891,Accuracy:0.6875\n",
      "训练迭代：10\n",
      "Test Loss:2.7476,Accuracy:0.6562\n",
      "训练迭代：11\n",
      "Test Loss:2.7399,Accuracy:0.6875\n",
      "训练迭代：12\n",
      "Test Loss:2.3730,Accuracy:0.7500\n",
      "训练迭代：13\n",
      "Test Loss:2.6614,Accuracy:0.7188\n",
      "训练迭代：14\n",
      "Test Loss:2.8543,Accuracy:0.6562\n",
      "训练迭代：15\n",
      "Test Loss:2.4802,Accuracy:0.7812\n",
      "训练迭代：16\n",
      "Test Loss:2.4901,Accuracy:0.8125\n",
      "训练迭代：17\n",
      "Test Loss:2.4695,Accuracy:0.7500\n",
      "训练迭代：18\n",
      "Test Loss:2.2672,Accuracy:0.7188\n",
      "训练迭代：19\n",
      "Test Loss:2.7622,Accuracy:0.6875\n",
      "训练迭代：20\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_epochs = 600\n",
    "    batch_size = 8\n",
    "    main(num_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d1af7-bcfc-429e-af4b-af48357b7720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
